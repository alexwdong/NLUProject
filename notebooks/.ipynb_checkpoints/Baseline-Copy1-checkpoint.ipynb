{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import BertTokenizer,BertModel\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from datasets import load_from_disk,load_dataset\n",
    "\n",
    "import pickle\n",
    "import logging\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnTheFlyDataset(Dataset):\n",
    "    def __init__(self, tensor):\n",
    "        self.tensor = tensor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.tensor.shape[0]\n",
    " \n",
    "    def __getitem__(self,idx):\n",
    "        return(self.tensor[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Quadro RTX 8000\n",
      "Memory Usage:\n",
      "Allocated: 0.4 GB\n",
      "Cached:    0.5 GB\n"
     ]
    }
   ],
   "source": [
    "data_dir = r'~/NLU_data/processed/20news'\n",
    "processed_dir = data_dir + '/'\n",
    "\n",
    "newsgroup_configs = ['bydate_alt.atheism',\n",
    "                     'bydate_comp.graphics',\n",
    "                     'bydate_comp.os.ms-windows.misc',\n",
    "                     'bydate_comp.sys.ibm.pc.hardware',\n",
    "                     'bydate_comp.sys.mac.hardware',\n",
    "                     'bydate_comp.windows.x',\n",
    "                     'bydate_misc.forsale',\n",
    "                     'bydate_rec.autos',\n",
    "                     'bydate_rec.motorcycles',\n",
    "                     'bydate_rec.sport.baseball',\n",
    "                     'bydate_rec.sport.hockey',\n",
    "                     'bydate_sci.crypt',\n",
    "                     'bydate_sci.electronics',\n",
    "                     'bydate_sci.med',\n",
    "                     'bydate_sci.space',\n",
    "                     'bydate_soc.religion.christian',\n",
    "                     'bydate_talk.politics.guns',\n",
    "                     'bydate_talk.politics.mideast',\n",
    "                     'bydate_talk.politics.misc',\n",
    "                     'bydate_talk.religion.misc']\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = ['bydate_alt.atheism',\n",
    "                         'bydate_comp.graphics',\n",
    "                         'bydate_comp.os.ms-windows.misc',\n",
    "                         'bydate_comp.sys.ibm.pc.hardware',\n",
    "                         'bydate_comp.sys.mac.hardware',\n",
    "                         'bydate_comp.windows.x',\n",
    "                         'bydate_misc.forsale',\n",
    "                         'bydate_rec.autos',\n",
    "                         'bydate_rec.motorcycles',\n",
    "                         'bydate_rec.sport.baseball',\n",
    "                         'bydate_rec.sport.hockey',\n",
    "                         'bydate_sci.crypt',\n",
    "                         'bydate_sci.electronics',\n",
    "                         'bydate_sci.med',\n",
    "                         'bydate_sci.space',\n",
    "                         'bydate_soc.religion.christian',\n",
    "                         'bydate_talk.politics.guns',\n",
    "                         'bydate_talk.politics.mideast',\n",
    "                         'bydate_talk.politics.misc',\n",
    "                         'bydate_talk.religion.misc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model= BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model.eval()\n",
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['train','test']\n",
    "split = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory ~/NLU_data/processed/20newstrain/bydate_alt.atheism not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-540defd6de42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewsgroup_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msubset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdataset_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mload_from_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_from_disk\u001b[0;34m(dataset_path, fs, keep_in_memory)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_dataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Directory {} not found\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_dataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset_info.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_in_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_in_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Directory ~/NLU_data/processed/20newstrain/bydate_alt.atheism not found"
     ]
    }
   ],
   "source": [
    "dataset_list = []\n",
    "label_to_label_idx_dict={}\n",
    "for config in newsgroup_configs:\n",
    "    subset_path = data_dir + split + '/' + config\n",
    "    dataset_list.append((config,load_from_disk(subset_path)))\n",
    "    \n",
    "for ii,label in enumerate(configs):\n",
    "    label_to_label_idx_dict[label]=ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8774006caa42a1a3b085525f37200b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=480.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2754 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a38bb7272241c4a60f1eda9b772ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=584.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136f0f4ed58e4659be605c2c3959dfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e68e92953b14d28b61053693983874e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=590.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df71bef8faf4b87923cfb16bad2be80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=578.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49a7d6f46114a239f94ae622674528b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=593.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7fba0e36c941fab8b7382af0b8e510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ad322012b64d56a3cd97fab7b2c498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=594.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a78d4425bc42dfaf0b6e0ed7593b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=598.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0628ebfb2e4caab2465f70852ccd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=597.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2c2efba6af4926a1006c17f117d711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce6e6b160c9423392575d2e85fd01d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=595.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08bce4b6767a47949adefa6415904f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a20f940f2d4b4086fdf2a157a7bbe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=594.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3aba72923a43c09b6fa7ff9fa1b252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=593.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbc8a67df6c4bc487145c3ec017bcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=599.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51dccad946d9499989957c65eb4f4573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=546.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25453087ad740ee8dfa8961941aae9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=564.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc835ac5305498e9dd90fff67b79664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=465.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed1ef4df0dd4d63b978a51731db1528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=377.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bert_encoded_segments_list = []\n",
    "for label, sub_dataset in dataset_list: #Loop over all dataset\n",
    "    \n",
    "    for entry in tqdm(sub_dataset): #Loop inside the dataset\n",
    "        # get text and CLS token\n",
    "        text = entry['text']\n",
    "        tokens = tokenizer.encode(text,add_special_tokens=False,return_tensors='pt')[0]\n",
    "        cls_token = tokenizer.encode(tokenizer.cls_token,add_special_tokens=False,return_tensors='pt')[0]\n",
    "        # Start the While loop - here, we try to get spans of 200 tokens, with a shift of 50. \n",
    "        # E.g if the sequence is 300 tokens, we get [0,199][50,249],[100,299]\n",
    "        start_index = 0\n",
    "        first_time = True\n",
    "        all_sub_seq = []\n",
    "        tokens_left = len(tokens)\n",
    "\n",
    "        while tokens_left > 0:\n",
    "            sub_seq = tokens[start_index:start_index+200]\n",
    "            #Update Tokens left\n",
    "            if first_time is True:\n",
    "                tokens_left -=200\n",
    "                first_time=False\n",
    "            else:\n",
    "                tokens_left -=50\n",
    "            # add start_idx\n",
    "            start_index+=50\n",
    "            # Add new sub_sequence to our list of sub_sequences\n",
    "            sub_seq_w_cls =torch.cat([cls_token,sub_seq]).unsqueeze(0)\n",
    "            if tokens_left <=0: #if this is the last run, make sure to pad the last sequence to be 201 tokens long:\n",
    "                sub_seq_w_cls = tokenizer.encode(sub_seq_w_cls.tolist()[0],padding='max_length',max_length=201,add_special_tokens=False,return_tensors='pt')\n",
    "            all_sub_seq.append(sub_seq_w_cls)\n",
    "\n",
    "        #cat to make a tensor\n",
    "        segments_tensor = torch.cat(all_sub_seq)\n",
    "        # turn all_sub_seq into an OnTheFlyDataset    \n",
    "        onthefly_dataset = OnTheFlyDataset(segments_tensor)\n",
    "        onthefly_loader =  DataLoader(onthefly_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "        #At this point, onthefly_datset/loader contains the tokens for one single \"long document\", in one dataset\n",
    "        with torch.no_grad():\n",
    "            batch_encoded_seg_list = []\n",
    "            for small_batch in onthefly_loader: #encode each segment in the long document\n",
    "                out = bert_model(input_ids=small_batch.to(device))\n",
    "                sub_bert_encoded_segments = out['last_hidden_state'][:,0,:]\n",
    "                batch_encoded_seg_list.append(sub_bert_encoded_segments)\n",
    "            bert_encoded_segments = torch.cat(batch_encoded_seg_list)\n",
    "            bert_encoded_segments_list.append((label_to_label_idx_dict[label],bert_encoded_segments.cpu()))\n",
    "    file_name = 'bert_encoded_segments_list_'\n",
    "    with open(processed_dir+ split+'\\\\' + file_name + 'baseline' +'.pkl', 'wb') as handle:\n",
    "        pickle.dump(bert_encoded_segments_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'\\\\wsl$\\Ubuntu-20.04\\home\\jolteon\\NLUProject\\data\\20news\\\\'\n",
    "processed_dir = data_dir + 'processed\\\\'\n",
    "with open(processed_dir+ split+'\\\\' + file_name + 'baseline' +'.pkl', 'wb') as handle:\n",
    "    pickle.dump(bert_encoded_segments_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bydate_talk.religion.misc'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_token = tokenizer.encode(tokenizer.cls_token,add_special_tokens=False,return_tensors='pt')[0]\n",
    "\n",
    "start_index = 0\n",
    "first_time = True\n",
    "all_sub_seq = []\n",
    "tokens_left = len(tokens)\n",
    "\n",
    "while tokens_left > 0:\n",
    "    sub_seq = tokens[start_index:start_index+200]\n",
    "    #Update Tokens left\n",
    "    if first_time is True:\n",
    "        tokens_left -=200\n",
    "        first_time=False\n",
    "    else:\n",
    "        tokens_left -=50\n",
    "    # add start_idx\n",
    "    start_index+=50\n",
    "    # Add new sub_sequence to our list of sub_sequences\n",
    "    sub_seq_w_cls =torch.cat([cls_token,sub_seq]).unsqueeze(0)\n",
    "    if tokens_left <=0: #if this is the last run, make sure to pad the last sequence to be 201 tokens long:\n",
    "        sub_seq_w_cls = tokenizer.encode(sub_seq_w_cls.tolist()[0],padding='max_length',max_length=201,add_special_tokens=False,return_tensors='pt')\n",
    "    all_sub_seq.append(sub_seq_w_cls)\n",
    "\n",
    "#cat to make a tensor\n",
    "segments_tensor = torch.cat(all_sub_seq)\n",
    "# turn all_sub_seq into an OnTheFlyDataset    \n",
    "segment_dataset = OnTheFlyDataset(segments_tensor)\n",
    "onthefly_loader =  DataLoader(onthefly_dataset, batch_size=8, shuffle=False, pin_memory=True)\n",
    "\n",
    "batch_encoded_seg_list = []\n",
    "for ii, small_batch in enumerate(onthefly_loader):\n",
    "    out = bert_model(input_ids=small_batch.to(device))\n",
    "    sub_bert_encoded_segments = out['pooler_output']\n",
    "    batch_encoded_seg_list.append(sub_bert_encoded_segments)\n",
    "bert_encoded_segments = torch.cat(batch_encoded_seg_list)\n",
    "bert_encoded_segments_list.append((label,bert_encoded_segments.cpu()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.OnTheFlyDataset at 0x21d38875490>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 201])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_seq_w_cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[101,\n",
       "  2129,\n",
       "  1998,\n",
       "  2043,\n",
       "  1010,\n",
       "  1998,\n",
       "  2025,\n",
       "  1010,\n",
       "  2005,\n",
       "  1996,\n",
       "  2087,\n",
       "  2112,\n",
       "  1010,\n",
       "  2040,\n",
       "  1998,\n",
       "  2339,\n",
       "  1012,\n",
       "  2671,\n",
       "  2001,\n",
       "  2947,\n",
       "  2141,\n",
       "  2041,\n",
       "  1997,\n",
       "  1996,\n",
       "  19176,\n",
       "  2015,\n",
       "  1005,\n",
       "  10628,\n",
       "  1010,\n",
       "  2776,\n",
       "  11122,\n",
       "  2075,\n",
       "  2185,\n",
       "  1996,\n",
       "  2129,\n",
       "  1998,\n",
       "  2043,\n",
       "  2096,\n",
       "  4321,\n",
       "  2975,\n",
       "  2369,\n",
       "  1996,\n",
       "  2040,\n",
       "  1998,\n",
       "  2339,\n",
       "  1012,\n",
       "  1996,\n",
       "  21591,\n",
       "  1010,\n",
       "  1996,\n",
       "  14337,\n",
       "  1010,\n",
       "  1996,\n",
       "  2046,\n",
       "  3917,\n",
       "  4630,\n",
       "  1010,\n",
       "  1998,\n",
       "  1996,\n",
       "  15818,\n",
       "  1010,\n",
       "  1997,\n",
       "  2607,\n",
       "  1010,\n",
       "  2145,\n",
       "  4366,\n",
       "  3691,\n",
       "  1999,\n",
       "  2035,\n",
       "  2176,\n",
       "  13100,\n",
       "  1012,\n",
       "  1028,\n",
       "  1064,\n",
       "  1028,\n",
       "  4138,\n",
       "  4419,\n",
       "  1010,\n",
       "  14405,\n",
       "  8093,\n",
       "  2080,\n",
       "  1010,\n",
       "  2149,\n",
       "  17167,\n",
       "  23597,\n",
       "  17287,\n",
       "  1028,\n",
       "  2106,\n",
       "  2066,\n",
       "  2115,\n",
       "  6594,\n",
       "  2105,\n",
       "  2572,\n",
       "  7898,\n",
       "  1010,\n",
       "  1998,\n",
       "  1045,\n",
       "  2106,\n",
       "  3275,\n",
       "  2041,\n",
       "  2054,\n",
       "  2572,\n",
       "  2232,\n",
       "  2001,\n",
       "  2013,\n",
       "  1028,\n",
       "  2115,\n",
       "  2434,\n",
       "  2695,\n",
       "  1024,\n",
       "  1011,\n",
       "  1007,\n",
       "  2172,\n",
       "  14723,\n",
       "  1012,\n",
       "  6057,\n",
       "  2129,\n",
       "  8866,\n",
       "  7166,\n",
       "  2000,\n",
       "  8494,\n",
       "  10362,\n",
       "  2477,\n",
       "  1010,\n",
       "  3475,\n",
       "  1005,\n",
       "  1056,\n",
       "  2009,\n",
       "  1029,\n",
       "  2092,\n",
       "  1010,\n",
       "  1045,\n",
       "  2572,\n",
       "  2469,\n",
       "  2045,\n",
       "  2024,\n",
       "  7564,\n",
       "  1997,\n",
       "  1000,\n",
       "  4045,\n",
       "  1000,\n",
       "  4325,\n",
       "  2923,\n",
       "  1000,\n",
       "  2128,\n",
       "  8569,\n",
       "  28200,\n",
       "  2015,\n",
       "  1000,\n",
       "  2041,\n",
       "  2045,\n",
       "  4873,\n",
       "  1010,\n",
       "  2130,\n",
       "  2065,\n",
       "  2027,\n",
       "  2031,\n",
       "  2000,\n",
       "  2022,\n",
       "  2580,\n",
       "  2013,\n",
       "  2498,\n",
       "  1012,\n",
       "  1031,\n",
       "  2074,\n",
       "  2005,\n",
       "  1996,\n",
       "  2501,\n",
       "  1010,\n",
       "  2153,\n",
       "  1010,\n",
       "  2572,\n",
       "  2232,\n",
       "  1027,\n",
       "  28141,\n",
       "  2135,\n",
       "  2715,\n",
       "  4286,\n",
       "  1033,\n",
       "  2190,\n",
       "  12362,\n",
       "  1024,\n",
       "  1011,\n",
       "  1007,\n",
       "  1010,\n",
       "  4138,\n",
       "  4419,\n",
       "  1010,\n",
       "  14405,\n",
       "  8093,\n",
       "  2080,\n",
       "  1010,\n",
       "  2149,\n",
       "  17167,\n",
       "  23597,\n",
       "  17287,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_seq_w_cls.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([195])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = all_sub_seq[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input tensor([[  101,  2129,  1998,  2043,  1010,  1998,  2025,  1010,  2005,  1996,\n          2087,  2112,  1010,  2040,  1998,  2339,  1012,  2671,  2001,  2947,\n          2141,  2041,  1997,  1996, 19176,  2015,  1005, 10628,  1010,  2776,\n         11122,  2075,  2185,  1996,  2129,  1998,  2043,  2096,  4321,  2975,\n          2369,  1996,  2040,  1998,  2339,  1012,  1996, 21591,  1010,  1996,\n         14337,  1010,  1996,  2046,  3917,  4630,  1010,  1998,  1996, 15818,\n          1010,  1997,  2607,  1010,  2145,  4366,  3691,  1999,  2035,  2176,\n         13100,  1012,  1028,  1064,  1028,  4138,  4419,  1010, 14405,  8093,\n          2080,  1010,  2149, 17167, 23597, 17287,  1028,  2106,  2066,  2115,\n          6594,  2105,  2572,  7898,  1010,  1998,  1045,  2106,  3275,  2041,\n          2054,  2572,  2232,  2001,  2013,  1028,  2115,  2434,  2695,  1024,\n          1011,  1007,  2172, 14723,  1012,  6057,  2129,  8866,  7166,  2000,\n          8494, 10362,  2477,  1010,  3475,  1005,  1056,  2009,  1029,  2092,\n          1010,  1045,  2572,  2469,  2045,  2024,  7564,  1997,  1000,  4045,\n          1000,  4325,  2923,  1000,  2128,  8569, 28200,  2015,  1000,  2041,\n          2045,  4873,  1010,  2130,  2065,  2027,  2031,  2000,  2022,  2580,\n          2013,  2498,  1012,  1031,  2074,  2005,  1996,  2501,  1010,  2153,\n          1010,  2572,  2232,  1027, 28141,  2135,  2715,  4286,  1033,  2190,\n         12362,  1024,  1011,  1007,  1010,  4138,  4419,  1010, 14405,  8093,\n          2080,  1010,  2149, 17167, 23597, 17287,     0,     0,     0,     0,\n             0]]) is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-31711608cded>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtemp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max_length'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m201\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\miniconda3\\envs\\NLUProject\\lib\\site-packages\\transformers-4.4.2-py3.8.egg\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[0;32m   2021\u001b[0m                 ``convert_tokens_to_ids`` method).\n\u001b[0;32m   2022\u001b[0m         \"\"\"\n\u001b[1;32m-> 2023\u001b[1;33m         encoded_inputs = self.encode_plus(\n\u001b[0m\u001b[0;32m   2024\u001b[0m             \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2025\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\miniconda3\\envs\\NLUProject\\lib\\site-packages\\transformers-4.4.2-py3.8.egg\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2337\u001b[0m         )\n\u001b[0;32m   2338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2339\u001b[1;33m         return self._encode_plus(\n\u001b[0m\u001b[0;32m   2340\u001b[0m             \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2341\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\miniconda3\\envs\\NLUProject\\lib\\site-packages\\transformers-4.4.2-py3.8.egg\\transformers\\tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m             )\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[0mfirst_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\miniconda3\\envs\\NLUProject\\lib\\site-packages\\transformers-4.4.2-py3.8.egg\\transformers\\tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    426\u001b[0m                     )\n\u001b[0;32m    427\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m    429\u001b[0m                         \u001b[1;34mf\"Input {text} is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m                     )\n",
      "\u001b[1;31mValueError\u001b[0m: Input tensor([[  101,  2129,  1998,  2043,  1010,  1998,  2025,  1010,  2005,  1996,\n          2087,  2112,  1010,  2040,  1998,  2339,  1012,  2671,  2001,  2947,\n          2141,  2041,  1997,  1996, 19176,  2015,  1005, 10628,  1010,  2776,\n         11122,  2075,  2185,  1996,  2129,  1998,  2043,  2096,  4321,  2975,\n          2369,  1996,  2040,  1998,  2339,  1012,  1996, 21591,  1010,  1996,\n         14337,  1010,  1996,  2046,  3917,  4630,  1010,  1998,  1996, 15818,\n          1010,  1997,  2607,  1010,  2145,  4366,  3691,  1999,  2035,  2176,\n         13100,  1012,  1028,  1064,  1028,  4138,  4419,  1010, 14405,  8093,\n          2080,  1010,  2149, 17167, 23597, 17287,  1028,  2106,  2066,  2115,\n          6594,  2105,  2572,  7898,  1010,  1998,  1045,  2106,  3275,  2041,\n          2054,  2572,  2232,  2001,  2013,  1028,  2115,  2434,  2695,  1024,\n          1011,  1007,  2172, 14723,  1012,  6057,  2129,  8866,  7166,  2000,\n          8494, 10362,  2477,  1010,  3475,  1005,  1056,  2009,  1029,  2092,\n          1010,  1045,  2572,  2469,  2045,  2024,  7564,  1997,  1000,  4045,\n          1000,  4325,  2923,  1000,  2128,  8569, 28200,  2015,  1000,  2041,\n          2045,  4873,  1010,  2130,  2065,  2027,  2031,  2000,  2022,  2580,\n          2013,  2498,  1012,  1031,  2074,  2005,  1996,  2501,  1010,  2153,\n          1010,  2572,  2232,  1027, 28141,  2135,  2715,  4286,  1033,  2190,\n         12362,  1024,  1011,  1007,  1010,  4138,  4419,  1010, 14405,  8093,\n          2080,  1010,  2149, 17167, 23597, 17287,     0,     0,     0,     0,\n             0]]) is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers."
     ]
    }
   ],
   "source": [
    "temp1 = tokenizer.encode(temp,padding='max_length',max_length=201,add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1.2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[50:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_seq = tokens[start_index:start_index+50]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_token+sub_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
