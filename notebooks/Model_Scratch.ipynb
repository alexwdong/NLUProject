{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3504ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer,BertModel\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from datasets import load_from_disk,load_dataset\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e23b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA GeForce RTX 3060 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20fc13c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "data_dir = r'\\\\wsl$\\Ubuntu-20.04\\home\\jolteon\\NLUProject\\data\\20news\\\\'\n",
    "processed_dir = data_dir + 'processed\\\\'\n",
    "split='train'\n",
    "file_name = 'bert_encoded_segments_list_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47adab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(processed_dir+ split+'\\\\' + file_name + str(threshold) +'.pkl', 'rb') as handle:\n",
    "    bert_encoded_segments_list = pickle.load(handle)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9aeca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "torch.Size([109, 768])\n",
      "tensor([0])\n",
      "torch.Size([319, 768])\n",
      "tensor([0])\n",
      "torch.Size([50, 768])\n",
      "tensor([0])\n",
      "torch.Size([15, 768])\n",
      "tensor([0])\n",
      "torch.Size([6, 768])\n",
      "tensor([0])\n",
      "torch.Size([55, 768])\n",
      "tensor([0])\n",
      "torch.Size([8, 768])\n",
      "tensor([0])\n",
      "torch.Size([13, 768])\n",
      "tensor([0])\n",
      "torch.Size([29, 768])\n",
      "tensor([0])\n",
      "torch.Size([4, 768])\n",
      "tensor([0])\n",
      "torch.Size([7, 768])\n"
     ]
    }
   ],
   "source": [
    "for ii, batch in enumerate(bert_encoded_segments_list):\n",
    "    label = batch[0]\n",
    "    temp = batch[1]\n",
    "    print(label)\n",
    "    print(temp.shape)\n",
    "    if ii == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "653d1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodedSegmentsDataset(Dataset):\n",
    "    def __init__(self,data_list):\n",
    "        self.data_list = data_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    " \n",
    "    def __getitem__(self,idx):\n",
    "        return(self.data_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df0131a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = EncodedSegmentsDataset(bert_encoded_segments_list)\n",
    "val_prop =.1\n",
    "bsize = 1\n",
    "\n",
    "dataset_size = len(encoded_dataset)\n",
    "val_size = int(val_prop * dataset_size)\n",
    "train_size = dataset_size - val_size\n",
    "\n",
    "train_dataset, val_dataset =  torch.utils.data.random_split(encoded_dataset,[train_size,val_size])\n",
    "encoded_train_loader = DataLoader(train_dataset,batch_size=bsize,shuffle=True, pin_memory=True)\n",
    "encoded_val_loader = DataLoader(val_dataset,batch_size=bsize,shuffle=True, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d741f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3]])\n",
      "torch.Size([1, 23, 768])\n",
      "tensor([-0.4808,  0.9906, -0.1408,  0.9914, -0.1096, -0.5517, -0.0907, -0.2929,\n",
      "         0.2146,  0.6552])\n",
      "tensor([[3]])\n",
      "torch.Size([1, 18, 768])\n",
      "tensor([-0.6152,  0.9913,  0.5027,  0.9831,  0.3775, -0.6378, -0.0582, -0.4697,\n",
      "         0.3518,  0.6874])\n",
      "tensor([[18]])\n",
      "torch.Size([1, 18, 768])\n",
      "tensor([-0.1982,  0.9835,  0.0502,  0.9774, -0.0878, -0.3492,  0.1402, -0.1665,\n",
      "         0.1323,  0.6186])\n"
     ]
    }
   ],
   "source": [
    "for ii, batch in enumerate(encoded_train_loader):\n",
    "    label = batch[0]\n",
    "    tensor = batch[1]\n",
    "    print(label)\n",
    "    print(tensor.shape)\n",
    "    print(tensor[0,0,10:20])\n",
    "    if ii ==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d618e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMoverBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.LSTM = nn.LSTM(input_size=768,hidden_size = 128,num_layers=1,batch_first=True)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(in_features=128,out_features=64)\n",
    "        self.linear2 = nn.Linear(in_features=64,out_features=20)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x,verbose=False):\n",
    "        \n",
    "        #print('input x:', x.shape)\n",
    "        LSTM_out,LSTM_states = self.LSTM(x)\n",
    "        #print('LSTM out:', LSTM_out.shape)\n",
    "        #print('LSTM states[0]:', LSTM_states[0].shape)\n",
    "        #print('LSTM states[1]:', LSTM_states[1].shape)\n",
    "        last_hidden_state = LSTM_states[0][0,:,:]\n",
    "        #last_embedding = LSTM_out[:,-1,:]\n",
    "        out = self.linear1(last_hidden_state)\n",
    "        #print('linear out', out.shape) if verbose\n",
    "        out = self.activation(out)\n",
    "        #print('activation out', out.shape) if verbose\n",
    "        out = self.linear2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa333d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoBERT_model = LSTMoverBERT()\n",
    "LoBERT_model.to(device)\n",
    "LoBERT_model.train()\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.Adam(LoBERT_model.parameters(),lr=0.00001,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef7fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52cc37ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3122c187924975a5d79c56faf737e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 train_loss: 2.9951916465611306 accuracy:  tensor(0.0528, device='cuda:0')\n",
      "Epoch: 0 val_loss: 2.994442713144709 accuracy:  tensor(0.0451, device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-50ae8f6931c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#Backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m#Record Metrics pt 2/2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\miniconda3\\envs\\NLUProject\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\miniconda3\\envs\\NLUProject\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\miniconda3\\envs\\NLUProject\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'betas'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\miniconda3\\envs\\NLUProject\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "train_accuracy_list = []\n",
    "val_accuracy_list = []\n",
    "\n",
    "for epoch in tqdm(range(30)):  # loop over the dataset multiple times\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    \n",
    "    #START TRAIN\n",
    "    LoBERT_model.train()\n",
    "    for idx, batch in enumerate(encoded_train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Define and move to GPU\n",
    "        label = batch[0][0]\n",
    "        model_input = batch[1]\n",
    "        label = label.to(device)\n",
    "        model_input = model_input.to(device)\n",
    "        # Forward Pass\n",
    "        out = LoBERT_model(model_input)\n",
    "        loss = criterion(out,label)\n",
    "        #Record Metrics pt 1/2\n",
    "        train_loss += loss.item()\n",
    "        pred = torch.argmax(out)\n",
    "        train_correct +=(pred == label).sum()\n",
    "        \n",
    "        #Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    #Record Metrics pt 2/2\n",
    "    train_loss = train_loss/ len(encoded_train_loader)\n",
    "    train_accuracy = train_correct/len(encoded_train_loader)\n",
    "    #Print and save\n",
    "    print('Epoch:', epoch, 'train_loss:',train_loss, 'accuracy: ',train_accuracy)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    \n",
    "    # START VAL\n",
    "    LoBERT_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(encoded_val_loader):\n",
    "            #Define and move to GPU\n",
    "            label = batch[0][0]\n",
    "            model_input = batch[1]\n",
    "            label = label.to(device)\n",
    "            model_input = model_input.to(device)\n",
    "            #Forward Pass\n",
    "            out = LoBERT_model(model_input)\n",
    "            loss = criterion(out,label)\n",
    "            #Record metrics pt 1/2\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            pred = torch.argmax(out)\n",
    "            val_correct +=(pred == label).sum()\n",
    "            \n",
    "    #Record metrics pt 2/2\n",
    "    val_loss = val_loss/ len(encoded_val_loader)\n",
    "    val_accuracy = val_correct/len(encoded_val_loader)\n",
    "    #Print and save\n",
    "    print('Epoch:', epoch, 'val_loss:',val_loss, 'accuracy: ',val_accuracy)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accuracy_list.append(val_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c20c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603bf0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df77f324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10afdc0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2673595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e69e33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c7265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a19af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7e305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0670c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef55f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e8fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b182ab51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
